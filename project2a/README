NAME: Alexander Ma
EMAIL: alexanderzma@hotmail.com
ID: 105093055

Question 2.1.1
It takes many iterations before errors are seen, because with few iterations, 
the threads may finish sequentially so they may not have any opportunity to 
conflict with each other. Also, even if they have the opportunity to conflict, 
there are much fewer opportunities, so the chance of conflicts actually 
occurring is much lower.
Significantly smaller numbers of iterations fail much less often, because 
there are much fewer opportunities for race conditions with significantly 
smaller numbers of iterations.

Question 2.1.2
--yield runs are slower, because they give up the CPU more often than the 
timer interrupt would force the program to give up the CPU. This means less of 
the program gets less work done per CPU time quanta.
The additional time is going to other threads running on the CPU and context 
switching.
It is not possible to get valid per-operation timings if we are using the 
--yield option. There are always competing background processes to run the CPU,
and these processes may not give back control to the adding thread in a 
consistent manner. This means that when the thread yields, it will get control 
back at an unknown time, which means that average measurements of this time are 
unreliable.

Question 2.1.3
The average cost per operation drops with increasing iterations, because the 
cost includes the time required to start the thread. This value is constant,
regardless of the number of iterations, so as the number of iterations 
increases, the time of starting the thread divided by the number of iterations 
decreases. With a constant number of threads, the time of starting threads 
divided by the number of operations decreases.
If the cost per iteration is a function of the number of iterations, we know 
the number of iterations to run by having a target cost, then having an input 
number of iterations to achieve that cost through the function.

Question 2.1.4
The options perform similarly for low numbers of threads, because there are 
fewer potential conflicts between threads for the lock to slow down the 
program.
The three protected operations slow down as the number of threads rises, 
because the protected operations are only performed essentially sequentially, 
due to the way the locks are set up. Therefore, fewer operations are done in 
a given amount of time. The unprotected operations do not have such a 
restriction.

Questions 2.2.1 and 2.2.2
The variation in time per mutex protected operation vs the number of threads 
in Part 1 is higher than the corresponding variation in Part 2. The variation 
in Part 1 between the mutexes with 1 and 2 threads is on the order of 100's of 
nanoseconds in magnitude. The variation in Part 2 between the mutexes with 1 
and 2 threads is on the order of tenths  and 1's of nanoseconds in magnitude, 
respectively.
The variation in Part 1 for 4 and 8 threads is on the order of 1000's of 
nanoseconds in magnitude. The variation in Part 2 for 4 and 8 threads is on the 
order of 10's of nanoseconds in magnitude.
The variation differences are due to the Part 1 operations being shorter, so 
they require the lock more often.
Some curves have an initial high slope and then level out gradually. They have 
this shape, because the initial increase is due to the cost of creating the 
threads, but the cost levels out, because as the number of threads increases, 
the cost of setting them up decreases, since some steps can be shared. Also, 
the increase in cost from lock conflicts decreases for every thread, because 
the percent increase of number of threads decreases as the number of threads 
increases.
Other curves are linear on log scale. This is because each thread has the 
potential to to conflict with every other thread, which could cause exponential 
increases in time, especially with spinlocks. Unfortunately, my locks in Part 2 
were partly implemented using spinlocks.
The spin lock has the highest rate of increase and is also the most linear in 
Part 1. This is because the spin lock chews up the CPU while waiting for the 
lock, so it hogs the CPU while waiting for a the lock to unlock, but hogging 
the CPU may slow down the process with the lock. Therefore, the spin lock is 
quite slow. The spin lock in Part 2 has a higher rate of increase than the 
mutex lock in Part 2, for the same reason. Part 2's spin lock is also close 
to linear.
Part 2's increases for the spin lock are higher, because there are more places 
where the lock is locked and released in Part 2's threads.
Part 2's increases for the mutex lock are higher, because there are more places 
to lock and release. Part 2's mutex also levels off slower, because there are 
more places to lock and release.
Part 2's graphs are thus linear on a log scale.
In Part 1, the mutex lock has a higher rate of increase than the CAS lock. 
The mutex lock prevents other threads from performing the same process, but 
the CAS lock allows other threads to do some action before they obtain the 
lock. Both locks have a similar shape, however.
In Part 1, the unprotected has the lowest increase, because it does not have 
to wait for any locks to continue with the program.
